{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import json\n",
    "from typing import List\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import json, sklearn, pickle, sys, re, os\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from transformers import *\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapd=pd.read_json(\"/home/ubuntu/project/arxiv-metadata-oai-snapshot.json\",  lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapd_hep_th = datapd.loc[datapd['categories'].str.contains('hep-th')]\n",
    "hep_abstracts = datapd_hep_th[ list(datapd_hep_th.iloc[:,0:1]) + ['abstract'] + ['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texttxt=hep_abstracts.abstract.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(text_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The limit 1325 helps makes sure that the max length of a given input is less than 512 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=open(\"/home/ubuntu/arxiv_small_roberta.txt\",\"w\")\n",
    "count=0\n",
    "for x in text_txt[0:140000]:\n",
    "    if len(x)<1325:\n",
    "        g.write(x)\n",
    "        g.write(\"\\n\")\n",
    "        count=count+1\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=open(\"/home/ubuntu/arxiv_dev_roberta.txt\",\"w\")\n",
    "count=0\n",
    "for x in text_txt[140000:140500]:\n",
    "    if len(x)<1325:\n",
    "        g.write(x)\n",
    "        g.write(\"\\n\")\n",
    "        count=count+1\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5b6716af72ed4b92\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"text\", data_files={\"train\": \"/home/ubuntu/project/arxiv_roberta.txt\",\"validation\": \"/home/ubuntu/project/arxivdev_roberta.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '  The problem of the gauge dependence of the fermion mass in the Maxwell-Chern-Simons QED$_{2+1}$ is revisited. Using Proca mass term as an intermediate infrared regulator we are demonstrating gauge-invariance of the fermion mass shell in QED$_{2+1}$ in all orders of the perturbation theory. '}\n",
      "{'text': '  We consider the integer QH state on Riemann surfaces with conical singularities, with the main objective of detecting the effect of the gravitational anomaly directly from the form of the wave function on a singular geometry. We suggest the formula expressing the normalisation factor of the holomorphic state in terms of the regularized zeta determinant on conical surfaces and check this relation for some model geometries. We also comment on possible extensions of this result to the fractional QH states. '}\n"
     ]
    }
   ],
   "source": [
    "print(datasets[\"train\"][0])\n",
    "print(datasets[\"validation\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Following the subtraction procedure for manifolds with boundaries, we calculate by variational methods, the Schwarzschild and Flat space energy difference. The one loop approximation for TT tensors is considered here. An analogy between the computed energy difference in momentum space and the Casimir effect is illustrated. We find a singular behaviour in the UV-limit, due to the presence of the horizon when $r=2m.$ When $r&gt;2m$ this singular behaviour disappears, which is in agreement with various other models previously presented.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the presence of a minimal length physical objects cannot collapse to an infinite density, singular, matter point. In this note we consider the possible final stage of the gravitational collapse of \"thick\" matter layers. The energy momentum tensor we choose to model these shell-like objects is a proper modification of the source for \"non-commutative geometry inspired\", regular black holes. By using higher momenta of Gaussian distribution to localize matter at finite distance from the origin, we obtain new solutions of the Einstein's equation which smoothly interpolates between Minkowski geometry near the center of the shell and Schwarzschild spacetime far away from the matter layer. The metric is curvature singularity free. Black hole type solutions exist only for \"heavy\" shells, i.e. $M\\ge M_{e}$, where $M_{e}$ is the mass of the extremal configuration. We determine the Hawking temperature and a modified Area Law taking into account the extended nature of the source.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We holographically investigate the scalarization in the Einstein-Scalar-Gauss-Bonnet gravity with a negative cosmological constant. We find that instability exists for both Schwarzschild-AdS and Reissner-Nordstrom-AdS black holes with planar horizons when we have proper interactions between the scalar field and the Gauss-Bonnet curvature corrections. We relate such instability to possible holographic scalarization and construct the corresponding hairy black hole solutions in the presence of the cosmological constant. Employing the holographic principle we expect that such bulk scalarization corresponds to the boundary description of the scalar hair condensation without breaking any symmetry, and we calculate the related holographic entanglement entropy of the system. Moreover, we compare the mechanisms of the holographic scalarizations caused by the effect of the coupling of the scalar field to the Gauss-Bonnet term and holographic superconductor effect in the presence of an electromagnetic field, and unveil their differences in the effective mass of the scalar field, the temperature dependent property and the optical conductivity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Several alternative approaches to quantum gravity problem suggest the modification of the {\\it fundamental volume $\\omega_{0}$} of the accessible phase space for representative points. This modified fundamental volume has a novel momentum dependence. In this paper, we study the effects of this modification on the thermodynamics of an ideal gas within the microcanonical ensemble and using the generalized uncertainty principle(GUP). Although the induced modifications are important only in quantum gravity era, possible experimental manifestation of these effects may provides strong support for underlying quantum gravity proposal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We present examples of 5d SCFTs that serve as counter-examples to a recently actively studied conjecture according to which it should be possible to obtain all 5d SCFTs by integrating out BPS particles from 6d SCFTs compactified on a circle. We further observe that it is possible to obtain these 5d SCFTs from 6d SCFTs if one allows integrating out BPS strings as well. Based on this observation, we propose a revised version of the conjecture according to which it should be possible to obtain all 5d SCFTs by integrating out both BPS particles and BPS strings from 6d SCFTs compactified on a circle. We describe a general procedure to integrate out BPS strings from a 5d theory once a geometric description of the 5d theory is given. We also discuss the consequences of the revised conjecture for the classification program of 5d SCFTs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infrared gravitons are continually produced during inflation. Like all particles, their contribution to the vacuum energy comes not only from their bare kinetic energy but also from the interactions they have with other gravitons. These interactions can be substantial -- despite the particles being highly infrared -- because they occur over the enormous spatial volume of the universe. Furthermore, the interactions grow with time evolution because more and more such gravitons come into causal contact with one another. Since gravity is universally attractive, these interactions can act to slow and eventually stop accelerated expansion.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We study the existence of hairy black holes in the generalized Einstein-Skyrme model. It is proven that in the BPS model limit there are no hairy black hole solutions, although the model admits gravitating (and flat space) solitons. Furthermore, we find strong evidence that a necessary condition for the existence of black holes with Skyrmionic hair is the inclusion of the Skyrme term $\\mathcal{L}_4$. As an example, we show that there are no hairy black holes in the $\\mathcal{L}_2+\\mathcal{L}_6+\\mathcal{L}_0$ model and present a new kind of black hole solutions with compact Skyrmion hair in the $\\mathcal{L}_4+\\mathcal{L}_6+\\mathcal{L}_0$ model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lattice QCD has the potential this decade to maximize the sensitivity of the entire flavor physics program to new physics and pave the way for understanding physics beyond the Standard Model at the LHC in the coming decade. However, the challenge for the Lattice is to demonstrate reliability at the level of a few per cent given a past history of 10-20% errors. The CLEO-c program at the Cornell Electron Storage Ring is providing the data that will make the demonstration possible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Perturbative Coulomb gauge Yang-Mills theory within the first order formalism is considered. Using a differential equation technique and dimensional regularization, analytic results for both the ultraviolet divergent and finite parts of the two-point functions at one-loop order are derived. It is shown how the non-ultraviolet divergent parts of the results are finite at spacelike momenta with kinematical singularities on the light-cone and subsequent branch cuts extending into the timelike region.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We discuss the lambda phi**4 model in 2- and 3-dimensional non-commutative spaces. The mapping onto a Hermitian matrix model enables its non-perturbative investigation by Monte Carlo simulations. The numerical results reveal a phase where stripe patterns dominate. In d=3 we show that in this phase the dispersion relation is deformed in the IR regime, in agreement with the property of UV/IR mixing. This \"striped phase\" also occurs in d=2. For both dimensions we provide evidence that it persists in the simultaneous limit to the continuum and to infinite volume (\"Double Scaling Limit\"). This implies the spontaneous breaking of translation symmetry.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-5b86afd5ccbddfe1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-8689509a076c9326.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-fd8d4296cf444171.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-ffe6c1bbab5d608d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-232e0b955f9d44df.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-a99d0adc6e785e0d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-60a03253bccacdc4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-df6777228c242354.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-50dae6a87a36b1a9.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-52f1e9c569aabab5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-31c7a5c965c51de1.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-ac9f435027f4536b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-c3b07f825fb3875e.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-a88d8db85aac0f37.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-beca1a65206b55cd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-40110f2b9645c42c.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=8, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'input_ids': [0,\n",
       "  1437,\n",
       "  166,\n",
       "  1455,\n",
       "  41,\n",
       "  7740,\n",
       "  7,\n",
       "  826,\n",
       "  4754,\n",
       "  26305,\n",
       "  3092,\n",
       "  6,\n",
       "  31612,\n",
       "  106,\n",
       "  15,\n",
       "  5,\n",
       "  1453,\n",
       "  9,\n",
       "  49,\n",
       "  1291,\n",
       "  19,\n",
       "  9553,\n",
       "  4903,\n",
       "  1538,\n",
       "  43603,\n",
       "  3092,\n",
       "  9,\n",
       "  17244,\n",
       "  4,\n",
       "  166,\n",
       "  34882,\n",
       "  5,\n",
       "  6945,\n",
       "  3892,\n",
       "  4621,\n",
       "  1492,\n",
       "  8,\n",
       "  37357,\n",
       "  17997,\n",
       "  21349,\n",
       "  11,\n",
       "  5,\n",
       "  29977,\n",
       "  982,\n",
       "  1453,\n",
       "  4,\n",
       "  1437,\n",
       "  2]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-dfb7bffbed7c0fe8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-ebd2755534a3e59f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-ba648e47d4adc52e.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-27606c54d768fbb4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-148174231f0cf7ec.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-44f51fb51f541155.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-b34c3b3dac1df2ef.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-95b79d9a21c680f6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-92e4d5de533219e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-04a83863ac0c803d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-fd17b9259cd874ed.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-d875b426ffbbd9af.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-cc8d7bda312547a5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-5eb3a9cd9cf3c6b1.arrow\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-409e71f47793c36c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-5b6716af72ed4b92/0.0.0/293ecb642f9fca45b44ad1f90c8445c54b9d80b95ab3fca3cfa5e1e3d85d4a57/cache-66cb6ff3433511ba.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>  The problem of the gauge dependence of the fermion mass in the Maxwell-Chern-Simons QED$_{2+1}$ is revisited. Using Proca mass term as an intermediate infrared regulator we are demonstrating gauge-invariance of the fermion mass shell in QED$_{2+1}$ in all orders of the perturbation theory. </s><s>  We present an introduction to Group Field Theory models, motivating them on the basis of their relationship with discretized BF models of gravity. We derive the Feynmann rules and compute quantum corrections in the coherent states basis. </s><s>  We study the closed-string spectrum of SU(N) gauge theories in the fundamental representation in 2+1 dimensions. We calculate the energies of the lowest lying ~ 30 states using a large variety of operators characterised by the quantum numbers of parity and longitudinal momentum. We find that our results for the ground state are very well approximated by the Nambu-Goto (NG) predictions even for short strings. For the excited states, we observe significant deviations from the NG predictions only for very short strings and they decrease rapidly with increasing string length. Finally, we see that Nambu-Goto provides a much better description of our results than the effective string theoretical predictions. We discuss the continuum and large-N limits. </s><s>  We study some aspects of localized tachyon condensation on non-supersymmetric orbifolds of the form $\\\\BC^2/\\\\BZ_n$ and $\\\\BC^3/\\\\BZ_n$. We discuss the gauged linear sigma models for these orbifolds. We show how several features of the decay of orbifolds of $\\\\BC^3$ can be realised in terms of orbifolds of $\\\\BC^2$. </s><s>  We compute the universal conductivity of the (2+1)-dimensional XY universality class, which is realized for a superfluid-to-Mott insulator quantum phase transition at constant density. Based on large-scale Monte Carlo simulations of the classical (2+1)-dimensional $J$-current model and the two-dimensional Bose-Hubbard model, we can precisely determine the conductivity on the quantum critical plateau, $\\\\sigma(\\\\infty)=0.359(4)\\\\sigma_Q$ with $\\\\sigma_Q$ the conductivity quantum. The universal conductivity curve is the standard example with the'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"/home/ubuntu/Roberta/robertasave\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  488367 KB |  488367 KB |  488367 KB |       0 B  |\n",
      "|       from large pool |  487680 KB |  487680 KB |  487680 KB |       0 B  |\n",
      "|       from small pool |     687 KB |     687 KB |     687 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  488367 KB |  488367 KB |  488367 KB |       0 B  |\n",
      "|       from large pool |  487680 KB |  487680 KB |  487680 KB |       0 B  |\n",
      "|       from small pool |     687 KB |     687 KB |     687 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  542720 KB |  542720 KB |  542720 KB |       0 B  |\n",
      "|       from large pool |  540672 KB |  540672 KB |  540672 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   54353 KB |   54558 KB |  265207 KB |  210854 KB |\n",
      "|       from large pool |   52992 KB |   52992 KB |  263162 KB |  210170 KB |\n",
      "|       from small pool |    1361 KB |    2045 KB |    2045 KB |     684 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     203    |     203    |     203    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     128    |     128    |     128    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     203    |     203    |     203    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     128    |     128    |     128    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      21    |      21    |      21    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      19    |      19    |      20    |       1    |\n",
      "|       from large pool |      18    |      18    |      19    |       1    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=/home/ubuntu/Roberta/robertasave, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=4, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Mar14_19-22-13_ip-172-31-36-211, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/home/ubuntu/Roberta/robertasave, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9619' max='9619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9619/9619 3:04:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.904700</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9619, training_loss=0.003238742601787527, metrics={'train_runtime': 11061.0702, 'train_samples_per_second': 0.87, 'total_flos': 14737871891893248, 'epoch': 1.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(tokenizer.encode(text_txt[0])).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  1437,    20,   936,     9,     5, 12567, 20748,     9,     5,\n",
      "           856,  8362,  1499,  2862,    11,     5, 15730,    12,   347, 16494,\n",
      "            12, 29656,  1790,  1209,  1691,  1629, 49747,   176,  2744,   134,\n",
      "         24303,  1629,    16, 25614,  4560,     4,  8630,  1698,  3245,  2862,\n",
      "          1385,    25,    41, 21398, 30175,  8199,    52,    32, 16987, 12567,\n",
      "            12, 24701,  1512,  2389,     9,     5,   856,  8362,  1499,  2862,\n",
      "         10785,    11,  1209,  1691,  1629, 49747,   176,  2744,   134, 24303,\n",
      "          1629,    11,    70,  3365,     9,     5, 32819, 13157,  1258,  6680,\n",
      "             4,  1437,     2]])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)\n",
    "input_ids = input_ids.to(device)\n",
    "output=model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.3.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's sample how the output looks like ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1437,    20, 43769,  1076,  1899,  3809,   281,     9,  1402,\n",
       "          1232,     9, 17997,  6287,  9781,    32,  1687,    11,  4617,     4,\n",
       "            20, 31625,  7721, 15256,   475,   982,   228,  1082,    36,   119,\n",
       "         37457,  1899,  1343,   176,   238,    19, 14712,    12,   858,  8774,\n",
       "         12514, 11324,    19,   121,  1640,   119,    43, 43769,     6,   223,\n",
       "            61,     5,  3091,  7891, 25935,  7223,   552,     5,  3206,    11,\n",
       "             5,  6451,   475,     8,    63, 21044,  3252,   877,  8985, 44128,\n",
       "          4901, 45152,   119, 48634,   166,   465,    14,   209,  6287,  9781,\n",
       "             6,   190,    19, 49830,   991, 23501, 24303, 48550,     9,   209,\n",
       "         11324,     6,    33,    10, 43769, 45429,    83,  1215,   119,   203,\n",
       "          2514,    87,   121,  1640,   119,   238,    61, 19659,    14,     5,\n",
       "          1007,   364,  8554, 26947,  1136,    88,  4723,    14,    13,   490,\n",
       "          9781,    36,   118,     4,   242,   482,   481, 16358,  1274,    43,\n",
       "            64,    28, 16274,    30,  1236,  5214,   288,     6,   112,     6,\n",
       "          8061,   734,     6,   226,     6,    13,     5,   132,   574,    12,\n",
       "         11953,  3206,     6,   215,    14,     5, 27462, 15668,     9,    70,\n",
       "           364,  8554, 43994,    11,     5,  1236,   212,  1293,    32, 20181,\n",
       "          3435,     5,   276,     8,   712,  6042,    19,  1236,     4,   286,\n",
       "           739,  1236,     6,   209, 27462, 15668,    32,   203,  2514,    87,\n",
       "           167,    14,    74,    28,   421,    31,     5,   121,  1640,   119,\n",
       "            43, 43769,  1937,     4,    20, 35961, 43769, 45429,    83,  1215,\n",
       "           119,  1640,   176,   574,    43, 10726,     9,  5990,    14, 17620,\n",
       "            11,    42,   980,     9,   982,    19,     5, 18465,   607,    12,\n",
       "         45743,   428, 45429,    14,    16,  5129,    30,     5,   278,     9,\n",
       "         14712,    12,   858,  8774, 12514, 10405,  1110,   131,    83,  1215,\n",
       "           119,  1640,   176,   574,    43,    16,    45,    10, 13262,   811,\n",
       "             4,   345,    32,  1122,   775,    13, 31716, 46246, 25286,  9781,\n",
       "            19,  5921,  1640,   119,  2744,   282, 15483,   282,    43, 43769,\n",
       "             9, 14712,    12,   858,  8774, 12514, 11324,     6,     8,    10,\n",
       "         24230,  8985,  3184,    13,  1367,  9781,    36,   118,     4,   242,\n",
       "           482, 27185, 16358,  1274,   322,    20, 42662,   594,  4458,    67,\n",
       "          3253,     7,     5, 14018,  3092,    14,    64,    28,  4756,    31,\n",
       "             5,  6287,  9781,    11,    10, 35729, 16093,    50,  2937, 36173,\n",
       "          2170,     4,    96,     5, 14018,  2777,     6,     5, 42662,   594,\n",
       "          4458, 16072,   142,     5, 37482,  1395,  2116,     4,   166,   617,\n",
       "          9914,  7281,   368,   785,     9, 30464,    36,  1990,     5,   490,\n",
       "          9781,    43,    30,  3736,  9781,   253,     7,   253,     4,    20,\n",
       "         24904,  1492,    13, 24165, 29105,     5,  7281,   368,  1152,     9,\n",
       "         30464, 16274,  1236,  1215,   134,     8,  1236,  1215,   176,   185,\n",
       "             5,   276,  1026,    25,     5,  8388,  4311,   611,    12,   534,\n",
       "         29742,   651,    13,  9557,  1640,   176,   322,   152,     8,    97,\n",
       "          6609,  1004,     5, 43769, 45429, 44128,   438,   250,  1215,   119,\n",
       "            88,    10, 21041, 13583,   506, 45429,     6,     8,    52,   311,\n",
       "            14,    42,    16, 45518, 30019,  3119,  6305, 17809,     7,     5,\n",
       "         17997,   333,   121,  1215,  1343,  1640,  9996,  1215,   176,    43,\n",
       "            13,   475,  5214,  1343,  2744,  1343, 49688,    12,   134, 48634,\n",
       "            20,   490,    12, 26149,   775,    32,  3112,     7,     5,  1200,\n",
       "          1721,   119, 15483, 41552,   132,    13,    61,     5,  1076,  1899,\n",
       "          3809,   281,    32,   117,  1181,  9031,   354,   757,  8293,   131,\n",
       "           209, 15256, 40764,  4971,    14,    32,  2008,    36,  3865,  3899,\n",
       "           337,    43,   882, 14831,     6,    50,  2232, 32819, 13157,  1635,\n",
       "         25991,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = text_txt[15215]\n",
    "sentence = tokenizer.encode(inp, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n",
    "senter=sentence.to(device)\n",
    "output=model(senter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "print(output[-1][2].shape)\n",
    "print(output[-1][11].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0704.0015'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iden=hep_abstracts['id'].values\n",
    "iden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 3072])\n",
      "torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "print(cat_hidden_states.size())\n",
    "cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "print(cat_sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 768])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecpy=output[-1][0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 768)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The pure spinor formulation of the ten-dimensional superstring leads to\\nmanifestly supersymmetric loop amplitudes, expressed as integrals in pure\\nspinor superspace. This paper explores different methods to evaluate these\\nintegrals and then uses them to calculate the kinematic factors of the one-loop\\nand two-loop massless four-point amplitudes involving two and four Ramond\\nstates.\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texttxt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0704.0015'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iden[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/roberta_model_mar14/tokenizer_config.json',\n",
       " '/home/ubuntu/roberta_model_mar14/special_tokens_map.json',\n",
       " '/home/ubuntu/roberta_model_mar14/vocab.json',\n",
       " '/home/ubuntu/roberta_model_mar14/merges.txt',\n",
       " '/home/ubuntu/roberta_model_mar14/added_tokens.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "output_dir = '/home/ubuntu/roberta_model_mar14/'\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(output_dir,output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"/home/ubuntu/roberta_model_mar10/\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.3.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We save 6 different kinds of vectors. Zeroth layer, first layer, second layer, last layer, average of last 4 layers and concatenation of last 4 layers ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time())\n",
    "f = open(\"mar_14_abstracts_roberta_epoch1_embeddings_v3.txt\", \"w\")\n",
    "f1 = open(\"mar_14_abstracts_roberta_epoch1_last4_average_v3.txt\", \"w\")\n",
    "f2 = open(\"mar_14_abstracts_roberta_epoch1_last4_concat_v3.txt\", \"w\")\n",
    "f3 = open(\"mar_14_abstracts_roberta_epoch1_last_v3.txt\", \"w\")\n",
    "f4 = open(\"mar_14_abstracts_roberta_epoch1_first_v3.txt\", \"w\")\n",
    "f5 = open(\"mar_14_abstracts_roberta_epoch1_second_v3.txt\", \"w\")\n",
    "for i in range(100):\n",
    "    f.write(f\"{iden[i]} \")\n",
    "    f1.write(f\"{iden[i]} \")\n",
    "    f2.write(f\"{iden[i]} \")\n",
    "    f3.write(f\"{iden[i]} \")\n",
    "    f4.write(f\"{iden[i]} \")\n",
    "    f5.write(f\"{iden[i]} \")\n",
    "\n",
    "    sentence = tokenizer.encode(texttxt[i], padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n",
    "    senter=sentence.to(device)\n",
    "    output=model(senter)\n",
    "    hidden_states=output[1]\n",
    "\n",
    "        \n",
    "    last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "    cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "    cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "    vec_cat=cat_sentence_embedding.detach().cpu().numpy()\n",
    "     \n",
    "    last_layer = hidden_states[-1] \n",
    "    last_sentence_embedding = torch.mean(last_layer, dim=1).squeeze()\n",
    "    vec_last=last_sentence_embedding.detach().cpu().numpy()\n",
    "        \n",
    "    zeroth_layer = hidden_states[0] \n",
    "    zeroth_sentence_embedding = torch.mean(zeroth_layer, dim=1).squeeze()\n",
    "    vec_zero=zeroth_sentence_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    first_layer = hidden_states[1] \n",
    "    first_sentence_embedding = torch.mean(first_layer, dim=1).squeeze()\n",
    "    vec_first=first_sentence_embedding.detach().cpu().numpy()\n",
    "    \n",
    "    second_layer = hidden_states[2] \n",
    "    second_sentence_embedding = torch.mean(second_layer, dim=1).squeeze()\n",
    "    vec_second=second_sentence_embedding.detach().cpu().numpy()\n",
    "        \n",
    "    average_layer=(hidden_states[-1]+hidden_states[-2]+hidden_states[-3]+hidden_states[-4])/4\n",
    "    avg_sentence_embedding = torch.mean(average_layer, dim=1).squeeze()\n",
    "    vec_avg=avg_sentence_embedding.detach().cpu().numpy()\n",
    "\n",
    "    f.write((' '.join(['%0.10f']*vec_zero.size)+'\\n') % tuple(vec_zero))\n",
    "    f1.write((' '.join(['%0.10f']*vec_avg.size)+'\\n') % tuple(vec_avg))\n",
    "    f2.write((' '.join(['%0.10f']*vec_cat.size)+'\\n') % tuple(vec_cat))\n",
    "    f3.write((' '.join(['%0.10f']*vec_last.size)+'\\n') % tuple(vec_last))\n",
    "    f4.write((' '.join(['%0.10f']*vec_last.size)+'\\n') % tuple(vec_first))\n",
    "    f5.write((' '.join(['%0.10f']*vec_last.size)+'\\n') % tuple(vec_second))\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "f.close()\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
