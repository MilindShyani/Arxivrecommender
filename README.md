# Arxiv Paper Recommender # 

**Oustanding Project Award, Deep Learning CS 230 Winter 2021, Stanford University** [Project report](http://cs230.stanford.edu/projects_winter_2021/reports/70758899.pdf)

The Arxiv serves one of the most essential needs of modern science i.e. providing openaccess to research. It has more than 1.8 million research papers as of today, with more than 15,000 submissions being added every month. This phenomenal rise of submissions has led to enormous progress in science, but has also made it harder for researchers to find papers closer to their research interests. Scientific papers contain subject specific jargon and knowledge, and a more complex semanticand logical structure. They are often difficult to understand even for humans, let alone a computer. As a result, it is hard to meaningfully search for them using text based inquiries only. Although traditional search engines, such as Google, provide search results based on advanced text similarity protocols, page-ranking algorithms, collaborative filtering and etc., a model that is fine tuned on a corpus of scientific papers, such as the Arxiv, would be invaluable. In this work, we address this important question by creating a contextual search engine and paper recommender by employing the powerful methods found recently by the ML community

Our central goal is to obtain meaningful embeddings for each paper based on its abstract. The embedding space is then used to create a paper recommender and a contextual search engine by using the cosine similarity distance between a given vector and the rest of the corpus. We employ six different methods to obtain the document embeddings for each paper and present them in increasing order of complexity. 

The folder [Jupyter](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/jupyter) contains the notebooks for 6 different architectures. The file [TFIDF_Doc2Vec clean](https://github.com/MilindShyani/Arxivrecommender/blob/main/arxiv/jupyter/TFIDF_Doc2Vec%20clean.ipynb) contains the TF-IDF and Doc2Vec architectures. In [LSTM](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/jupyter/LSTM), we employ an LSTM recurrent neural network with a proxy task of paper title prediction to fine tune Word2Vec embeddings. These word embeddings are then used to obtain better paper embeddings and recommendations. In [GPT-2](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/jupyter/GPT-2), [RoBERTA](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/jupyter/RoBERTa) and [SBERT](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/jupyter/SBERT) we fine-tune GPT-2, RoBERTa and Sentence-BERT on the high energy physics abstracts corpus to obtain more meaningful document embeddings respectively.

Due to the absence of a database of paper preferences of several users, we formulate three novel metrics based on co-citations, relevance and novelty to judge performance. We elaborate upon these metrics in section 5 of our [project report](http://cs230.stanford.edu/projects_winter_2021/reports/70758899.pdf) and argue that our models are at par with the current state of the art. The problem of finding a quantifiable metric to rate “good” recommendations (purely based on content) is almost as hard as the problem itself but we believe that the combination of our three metrics provides a necessary, if not sufficient, measure of performance.


The script for obtaining co-citation counts using the Inspire API can be found in the folder [python](https://github.com/MilindShyani/Arxivrecommender/tree/main/arxiv/python). 
